---
layout:       post
title:        廊坊人工智能培训
subtitle:     Lafang cultivate
date:         2024-5-21
author:       whiteicey
header-img:   img/yolo.png
catalog:      true
tags:
    - Python
    - Machine Learning
    - Deep Learning
    - Artificial Intelligence Platform
    - Computing Platform
---

# 前言

本次人工智能平台培训主要介绍了认知计算平台（E8），其中在参会期间我产生了以下疑惑，以及关于这些疑惑的讨论

# 人工智能平台

1. 可视化低代码部分是否真的有价值？

    首先值得肯定的是，E8平台展示的低代码可视化效果非常优秀，通过拖拽算子的形式将模型的搭建转变为了与scratch类似的图形化编程，让一个模型建立的过程更加清晰且直观，再通过手动添加参数的形式完成整个工程。

    这种尝试固然值得肯定，但是我们需要思考的是，这样的做法真的值得花费这样大的精力吗？我对此持质疑的态度，首先如果一个会开发的人，那么他需要的不是一个个算子拖来拖去，而是像类似于[ruoyi框架](http://120.79.202.7/)一样提供可复用的Vue框架后自行修改即可
    
    这种只提供可视化界面的行为看似提供了开发效率实际上真正的影响是开发人员对模型细节参数的无法真正掌握，正如[Pytorch](https://pytorch.org/)虽然相较于[TensorFlow](https://tensorflow.google.cn/?hl=zh-cn)有着更优秀的封装程度和易用的API接口，但是TesnsorFlow依旧保留着大量的拥簇，这正是因为[Pytorch](https://pytorch.org/)的封装程度过高难以对模型进行更精细的调参导致的，毕竟深度学习本身就是调参的艺术，在理想化的实验中，我们可以忽略梯度，可以无视版本冲突带来的的warning，但是在生产中，一切的细节都值得被仔细打磨，所以一切看似便利的背后往往都隐藏着绕不开的深坑

    这个平台是交由初学者使用的吗？在我看来，他的初心也许于此，但是在实际演示中却又完全脱离了这一点，如果作为一个新手，那么他对于每个算子的意义和参数设置的价值都是未知的，更何况这东西甚至大部分人都无法说清楚，毕竟深度学习发展到今天，新增的优化器和调参的技巧数不胜数，选择更是多如牛毛，让初学者根据合适的情况自行选择本就是痴人说梦

    所以从结果来看，这个平台真正的作用已经脱离了开发完全走上了为了演示而演示的平台，比起满足需求，更像是创造了一个新需求，给来检查的领导提供情绪价值

    但是如果一定要找到一个使用场景呢？我想还是有的，那就是面向那些对算法和模型极为了解但却不太擅长代码编写的数学人才了，这样的平台切实的能解决他们的问题，并且根据他们搭建的模型也可以更清晰的像开发人员展示清晰的需求

2. 在模型推荐方向，相较于我们大量使用的huggingface，kaggle比较如何？

    询问了一下相关人员，被告知目前平台的推荐只满足机器学习，而对深度学习相关部分还未实现，下图展示了huggingface提供的开源模型

![huggingface](/img/huggingface.png)

# 算力平台

1. 算力是否充足，相较于Google colab和kaggle是否有选择的价值？

    咨询了一下目前平台的算力，大约有30张卡（4张V100，30张v100s），并且计划将这个平台提供给全国各级单位使用，而京东科技就该部门，有不少于1000张卡，且型号多为：A100 A800 L40S

# 算法案例

1. 算法是否具备迁移和部署的能力？

    目前是暂时不支持任何的模型导出，只提供相关的API接口进行调用，也不支持模型代码的下载，那么几乎可以认为这个平台提供的模型几乎不具备迁移和脱离平台后的部署能力

# 知识图谱

自然语言处理中的困难：1.歧义 2.阅读理解/暗示/上下文关联 3.分词短句/多义词

知识图谱是基于图的数据结构  ——>  图的三要素：顶点，边，属性

图谱的答案更加固定，标准化，但是大模型的答案取决于问法，所以在目前模型还无法取代图谱

>知识图谱和大模型的融合：
>
>1.做训练语料，领域性，行业性，通识性的没有必要 
>
>2.图谱做知识检索问答，通过图谱识别关键字，提供给给大模型问答；大模型做知识抽取后交给图谱做知识对齐


>专业领域的大模型是否会取代知识图谱：
>
>1.大模型的存在幻觉问题，答案是否准确不确定
>
>2.大模型的特点是开箱即用，但是知识修正比较差
>
>3.从需求出发自行选择


>提高响应速度的办法？
>
>1.bert模型，以法律智能问答系统这类典型的FAQ为例，我们可以考虑通过对库内预留答案进行预编码以及加入检索模型双塔模型进行优化，一方面我们对输入的question编码后输入一个bert，另一方面可以提前准备好的预编码query也送入一个bert，之后再根据query和question的组合进行评分
>
>2.大模型的优化是优化第一个token的生成时间