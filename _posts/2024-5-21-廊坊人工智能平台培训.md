---
layout:       post
title:        廊坊人工智能培训
subtitle:     Lafang cultivate
date:         2024-5-21
author:       whiteicey
header-img:   img/yolo.png
catalog:      true
tags:
    - Python
    - Machine Learning
    - Deep Learning
    - Artificial Intelligence Platform
    - Computing Platform
---

# 前言

本次人工智能平台培训主要介绍了认知计算平台（E8），其中在参会期间我产生了以下疑惑，以及关于这些疑惑的讨论

# 人工智能平台

1. 可视化低代码部分是否真的有价值？

    首先值得肯定的是，E8平台展示的低代码可视化效果非常优秀，通过拖拽算子的形式将模型的搭建转变为了与scratch类似的图形化编程，让一个模型建立的过程更加清晰且直观，再通过手动添加参数的形式完成整个工程。

    这种尝试固然值得肯定，但是我们需要思考的是，这样的做法真的值得花费这样大的精力吗？我对此持质疑的态度，首先如果一个会开发的人，那么他需要的不是一个个算子拖来拖去，而是像类似于[ruoyi框架](http://120.79.202.7/)一样提供可复用的Vue框架后自行修改即可
    
    这种只提供可视化界面的行为看似提供了开发效率实际上真正的影响是开发人员对模型细节参数的无法真正掌握，正如[Pytorch](https://pytorch.org/)虽然相较于[TensorFlow](https://tensorflow.google.cn/?hl=zh-cn)有着更优秀的封装程度和易用的API接口，但是TesnsorFlow依旧保留着大量的拥簇，这正是因为[Pytorch](https://pytorch.org/)的封装程度过高难以对模型进行更精细的调参导致的，毕竟深度学习本身就是调参的艺术，在理想化的实验中，我们可以忽略梯度，可以无视版本冲突带来的的warning，但是在生产中，一切的细节都值得被仔细打磨，所以一切看似便利的背后往往都隐藏着绕不开的深坑

    这个平台是交由初学者使用的吗？在我看来，他的初心也许于此，但是在实际演示中却又完全脱离了这一点，如果作为一个新手，那么他对于每个算子的意义和参数设置的价值都是未知的，更何况这东西甚至大部分人都无法说清楚，毕竟深度学习发展到今天，新增的优化器和调参的技巧数不胜数，选择更是多如牛毛，让初学者根据合适的情况自行选择本就是痴人说梦

    所以从结果来看，这个平台真正的作用已经脱离了开发完全走上了为了演示而演示的平台，比起满足需求，更像是创造了一个新需求，给来检查的领导提供情绪价值

    但是如果一定要找到一个使用场景呢？我想还是有的，那就是面向那些对算法和模型极为了解但却不太擅长代码编写的数学人才了，这样的平台切实的能解决他们的问题，并且根据他们搭建的模型也可以更清晰的像开发人员展示清晰的需求

2. 在模型推荐方向，相较于我们大量使用的huggingface，kaggle比较如何？

    询问了一下相关人员，被告知目前平台的推荐只满足机器学习，而对深度学习相关部分还未实现，下图展示了huggingface提供的开源模型

![huggingface](/img/huggingface.png)

# 算力平台

1. 算力是否充足，相较于Google colab和kaggle是否有选择的价值？

    咨询了一下目前平台的算力，大约有30张卡（4张V100，30张v100s），并且计划将这个平台提供给全国各级单位使用，而京东科技就该部门，有不少于1000张卡，且型号多为：A100 A800 L40S

# 算法案例

1. 算法是否具备迁移和部署的能力？

    目前是暂时不支持任何的模型导出，只提供相关的API接口进行调用，也不支持模型代码的下载，那么几乎可以认为这个平台提供的模型几乎不具备迁移和脱离平台后的部署能力

# 知识图谱

自然语言处理中的困难：1.歧义 2.阅读理解/暗示/上下文关联 3.分词短句/多义词

知识图谱是基于图的数据结构  ——>  图的三要素：顶点，边，属性

图谱的答案更加固定，标准化，但是大模型的答案取决于问法，所以在目前模型还无法取代图谱

Q:知识图谱和大模型的融合：
>
>1.做训练语料，领域性，行业性，通识性的没有必要 
>
>2.图谱做知识检索问答，通过图谱识别关键字，提供给给大模型问答；大模型做知识抽取后交给图谱做知识对齐


Q:专业领域的大模型是否会取代知识图谱：
>
>1.大模型的存在幻觉问题，答案是否准确不确定
>
>2.大模型的特点是开箱即用，但是知识修正比较差
>
>3.从需求出发自行选择


Q:提高响应速度的办法？
>
>1.bert模型，以法律智能问答系统这类典型的FAQ为例，我们可以考虑通过对库内预留答案进行预编码以及加入检索模型双塔模型进行优化，一方面我们对输入的question编码后输入一个bert，另一方面可以提前准备好的预编码query也送入一个bert，之后再根据query和question的组合进行评分
>
>2.大模型的优化是优化第一个token的生成时间

# 大模型

Q:大模型是否在油气领域有真正的应用场景？我能想到的工作均为文书工作

>强化检索，建立知识库，专业模型用于报告生成

Q:大模型存在幻觉问题，请问如何解决这个问题在报告上解决这个问题

>大模型可以用于报告检测，但是还是需要人工后续审核
>
>以及可以考虑通过微调等方案进行调整，而非一定预训练


Q:模型是否适合于回答非常精准的问题？

>这个问题可以通过对回答做限制做到，让大模型的回答内容限制在我们准备的知识库里实现

Q:GPT的部署成本过高，即使是剪枝后的专业化模型也需要4张A100的显卡

>可以考虑使用清华智谱的6b开源模型，可以用消费级显卡
>
>先部署起来，再积累语料，再谈迭代

Q:是否有后续的规划，比如与A2，A5平台这种数据源对接，能否成为通用模型？

>和梦想云结合过，项目为测井识别，对接需要从业务需求来看，不可能完全对接
>
>对于统建的数据湖接入不清楚

Q:这个平台是底座吗？我们需要规划什么？

>人工智能平台是集团公司建立的，但是后续主要用于什么方向不清楚

# 提示词工程

专业语料加工（知识图谱、问答对）-> 提示词工程 -> 检索增强生成 -> 工具使用学习 -> 微调 -> 增量训练

要注重模型的均衡能力，过早微调会导致性能失衡

寻找场景：勘探研究院 -> 辅助文献阅读 -> 协助编写工作报告和技术报告

Q:为什么需要PE（提示词工程）

>1.提高模型新歌能
>
>2.引导模型输出
>
>3.拓展模型应用

Q:是否一定需要PE？

>最早搜索引擎问世时有很多搜索专家，精通许多奇巧淫技，但是随着搜索技术发展，他们都被淘汰了，但是目前LLM还在发展早期，所以再短期内需要，长期等待发展

PE设计原则及方法论：准确性原则，可拓展性原则，间接性原则，实验验证

提示词模板：指令（instruction），上下文（context），问题（input date），输出格式（output indicator）

提示词给了效果比不给好，即使时错误的提示词也有用

思维链技术：离散式上下文学习 举例：先给简单样例后再给出更难二弟题目求得解答 拆解问答过程获得更好的结果

思维链Acc 78.7   提示词 17.7

自洽思维链 https://arxiv.org/abs/2203.11171

由易到难的思维链技术 https://arxiv.org/abs/2205.10625

OpenAI推荐的提示词编写公式

![PE](/img/sixstep.jpg)

COSTAR模板，即语境结构化提示，是一个允许用户以向语言模型提供语境和指导的方式构建提示的框架。它在提示中融入了语境、任务规范和示例等元素。首先通过分解首字母缩略词来了解其组成部分：

C-Context：在提示中嵌入背景，引导模型理解任务。 

例如：分析电影评论的情感。

Analyze the sentiment of a user review for a movie.

O-Output Format：指定期望的回复格式。 

例如：提供情感标签（正面、负面或中性），并简要说明理由。

Provide a sentiment label (positive, negative, or neutral) along with a brief justification.

S-Specifications：明确任务的具体要求和约束，引导模型关注点。 

例如：关注整体情感，不涉及具体细节。既要考虑明确的表达，也要考虑含蓄的表达。

Focus on the overall sentiment without getting into specific details. Consider both explicit and implicit expressions.

T-Task Eamples：在提示中加入具体任务的示例，说明期忘的行为。 

例如：如果用户对故事情节表达了喜悦之情，模型应将其识别并标记为积极情绪。

If the user expresses joy about the story-line, the model should identify and label it as a positive sentiment.

A-Additional Information：在提示中补充任意的附加信息，以加深模型的理解能力。 

例如：电影类型是爱情喜剧。

The movie genre is a romantic comedy.

R-Restrictions：设定界限和限制，引导模型在指定范围内执行任务。 

例如：回复最多不超过三句话。

Limit the response to a maximum of three sentences.

Petro AI用的是通用大模型，但是没有做增量预训练

# 总结

优势：

1. 有很强的意愿在AI领域提升，集团公司总推

2. 有广泛的市场需求，从勘探研究院的报告能看出，主要体现在知识图谱和文书工作方面

3. 基础设施建设完善，有数据湖作为基建支撑，未来的数据来源不会成为限制

4. 有较强的技术支撑，华为，科大讯飞有强烈的合作意愿

劣势：

1. 硬件资源受限，算力过于贫乏，比起顶级大学的实验室都算弱

2. 需求不明确，或者说需求笼统难以明确，未来需要大量懂生产和计算机技术的人员作为桥梁沟通明确才行

3. 大模型的应用依旧流于表面，没有真正深入到生产需求上的项目，甚至没有用于辅助决策，而只能作为事后总结的辅助

4. 基层设施建设老旧，能否真正下沉项目我暂且存疑

5. 对模型没有真正所有权，一切的建设都是基于开源模型，也就意味着在真正搭建油气领域的专属AI时会过度模型的提供方

6. 截至目前全世界所有的AI模型，几乎都没有深入生产的案例，如果硬要说的话，那也许智能驾驶算半个，所以在生产+AI的领域我们是没有作业能抄的，一切的一切都将基于经验和摸索，其中有大量的时间成本和经济成本

7. 从目前的投入来看，大量的成本被用于实现前端展示，而在真正技术难度难以攻克的模型，生产结合上几乎没有，无非就是重复业界现成的解决方案然后复现，当然，也不能忽视的是其实集团公司提供的支持并没有我们想象中的多，毕竟从算力平台的能量就能看出来，所以我很怀疑集团公司是否有真正持续的热情去烧一个也许未来十年都看不到实际生产产出的项目